{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "analysis = {\"mse\":[],\n",
    "            \"total_lesions\":[],\n",
    "            \"max_lesion_volume\":[],\n",
    "            \"min_lesion_volume\":[],\n",
    "            \"total_volume_of_lesions\":[],\n",
    "            \"average_volume\":[],\n",
    "            \"median_volume\":[],\n",
    "            \"inf_total_lesions\":[],\n",
    "            \"inf_max_lesion_volume\":[],\n",
    "            \"inf_min_lesion_volume\":[],\n",
    "            \"inf_total_volume_of_lesions\":[],\n",
    "            \"inf_average_volume\":[],\n",
    "            \"inf_median_volume\":[],\n",
    "            \"jux_total_lesions\":[],\n",
    "            \"jux_max_lesion_volume\":[],\n",
    "            \"jux_min_lesion_volume\":[],\n",
    "            \"jux_total_volume_of_lesions\":[],\n",
    "            \"jux_average_volume\":[],\n",
    "            \"jux_median_volume\":[],\n",
    "            \"per_total_lesions\":[],\n",
    "            \"per_max_lesion_volume\":[],\n",
    "            \"per_min_lesion_volume\":[],\n",
    "            \"per_total_volume_of_lesions\":[],\n",
    "            \"per_average_volume\":[],\n",
    "            \"per_median_volume\":[],\n",
    "            \"sub_total_lesions\":[],\n",
    "            \"sub_max_lesion_volume\":[],\n",
    "            \"sub_min_lesion_volume\":[],\n",
    "            \"sub_total_volume_of_lesions\":[],\n",
    "            \"sub_average_volume\":[],\n",
    "            \"sub_median_volume\":[],\n",
    "           }\n",
    "les_type = ['inf','jux','per','sub']\n",
    "\n",
    "#import table and leave only important values\n",
    "df = pd.DataFrame.from_csv(\"lesion_info.csv\",index_col=False)\n",
    "df.drop(df.columns[[0,2,3,4,5,6]],axis=1,inplace=True)\n",
    "#organize table by mseID and lesion type\n",
    "df1 = pd.pivot_table(df, values=[\"volume\",\"distance from midbrain\",\"distance from ventricles\",\"distance from gray matter\"], index = [\"mseID\",\"type\",\"lesion\"])\n",
    "#function that removes zeros and gives values as array\n",
    "def remove_zeros(df):\n",
    "    df1 = df.unstack(level=1,fill_value=0)\n",
    "    df1 = df1.stack(dropna=False)\n",
    "    return df1.values\n",
    "#call specific index\n",
    "df2 = df1.groupby(level=[0,1])\n",
    "df3 = df1.groupby(level=[0])\n",
    "#gather important statistics and place into callable arrays\n",
    "count_les = remove_zeros(df2.count())\n",
    "sum_les = remove_zeros(df2.sum())\n",
    "max_les = remove_zeros(df2.max())\n",
    "min_les = remove_zeros(df2.min())\n",
    "ave_les = remove_zeros(df2.mean())\n",
    "med_les = remove_zeros(df2.median())\n",
    "\n",
    "count_tot = df3.count().values\n",
    "sum_tot = df3.sum().values\n",
    "max_tot = df3.max().values\n",
    "min_tot = df3.min().values\n",
    "ave_tot = df3.mean().values\n",
    "med_tot = df3.median().values\n",
    "#loop all important information into new table\n",
    "subjects = df1.index.get_level_values(0).unique()\n",
    "for x in range(len(subjects)):\n",
    "    analysis['mse'].append(subjects[x])\n",
    "    analysis[\"total_lesions\"].append(count_tot[x][3])\n",
    "    analysis[\"max_lesion_volume\"].append(max_tot[x][3])\n",
    "    analysis[\"min_lesion_volume\"].append(min_tot[x][3])\n",
    "    analysis[\"total_volume_of_lesions\"].append(sum_tot[x][3])\n",
    "    analysis[\"average_volume\"].append(ave_tot[x][3])\n",
    "    analysis[\"median_volume\"].append(med_tot[x][3])\n",
    "    for y in range(len(les_type)):\n",
    "        count = (x * 4) + y\n",
    "        analysis[\"%s_total_lesions\" % les_type[y]].append(count_les[count][3])\n",
    "        analysis[\"%s_max_lesion_volume\" % les_type[y]].append(max_les[count][3])\n",
    "        analysis[\"%s_min_lesion_volume\" % les_type[y]].append(min_les[count][3])\n",
    "        analysis[\"%s_total_volume_of_lesions\" % les_type[y]].append(sum_les[count][3])\n",
    "        analysis[\"%s_average_volume\" % les_type[y]].append(ave_les[count][3])\n",
    "        analysis[\"%s_median_volume\" % les_type[y]].append(med_les[count][3])\n",
    "\n",
    "lesion_info = pd.DataFrame(analysis,columns= [  \"mse\",\n",
    "                                                \"total_lesions\",\n",
    "                                                \"max_lesion_volume\",\n",
    "                                                \"min_lesion_volume\",\n",
    "                                                \"total_volume_of_lesions\",\n",
    "                                                \"average_volume\",\n",
    "                                                \"median_volume\",\n",
    "                                                \"inf_total_lesions\",\n",
    "                                                \"inf_max_lesion_volume\",\n",
    "                                                \"inf_min_lesion_volume\",\n",
    "                                                \"inf_total_volume_of_lesions\",\n",
    "                                                \"inf_average_volume\",\n",
    "                                                \"inf_median_volume\",\n",
    "                                                \"jux_total_lesions\",\n",
    "                                                \"jux_max_lesion_volume\",\n",
    "                                                \"jux_min_lesion_volume\",\n",
    "                                                \"jux_total_volume_of_lesions\",\n",
    "                                                \"jux_average_volume\",\n",
    "                                                \"jux_median_volume\",\n",
    "                                                \"per_total_lesions\",\n",
    "                                                \"per_max_lesion_volume\",\n",
    "                                                \"per_min_lesion_volume\",\n",
    "                                                \"per_total_volume_of_lesions\",\n",
    "                                                \"per_average_volume\",\n",
    "                                                \"per_median_volume\",\n",
    "                                                \"sub_total_lesions\",\n",
    "                                                \"sub_max_lesion_volume\",\n",
    "                                                \"sub_min_lesion_volume\",\n",
    "                                                \"sub_total_volume_of_lesions\",\n",
    "                                                \"sub_average_volume\",\n",
    "                                                \"sub_median_volume\"])\n",
    "lesion_info.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#command that outputs histogram of number of instances\n",
    "pd.value_counts(lesion_info['total_lesions'],sort=False)\n",
    "per_lesions = lesion_info['per_total_lesions'] == 0\n",
    "sub_lesions = lesion_info['sub_total_lesions'] >= 2\n",
    "qc = lesion_info[per_lesions][['mse','total_lesions','per_total_lesions','sub_total_lesions']]\n",
    "qc.count()\n",
    "#can call columns by (variable).(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lesion_info[lesion_info['min_lesion_volume'] <= 10]\n",
    "\n",
    "#added this comment to see if merging is successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#obtain EDSS scores\n",
    "clinical_data = pd.DataFrame.from_csv('/data/henry1/keshavan/lesion_seg/notebooks/demographics.csv')\n",
    "edss = clinical_data['metric'] == 'EDSS'\n",
    "dc = clinical_data['metric'] == 'DiseaseCourse'\n",
    "dd = clinical_data['metric'] == 'DiseaseDuration'\n",
    "msfc251 = clinical_data['metric'] == 'MSFC 25FTW Trial1 Seconds'\n",
    "msfc252 = clinical_data['metric'] == 'MSFC 25FTW Trial2 Seconds'\n",
    "ms = clinical_data['msid'] == 'ms0056'\n",
    "edss_scores = clinical_data[edss][['mse','msid','value']].rename(columns={'value':'edss'}).sort_values('mse',axis=0).reset_index().drop('index',axis=1)\n",
    "dd_scores = clinical_data[dd][['mse','msid','value']].rename(columns={'value':'dd'}).sort_values('mse',axis=0).reset_index().drop('index',axis=1)\n",
    "msfc251_scores = clinical_data[msfc251][['mse','msid','value']].rename(columns={'value':'msfc 25 1'}).sort_values('mse',axis=0).reset_index().drop('index',axis=1)\n",
    "msfc252_scores = clinical_data[msfc252][['mse','msid','value']].rename(columns={'value':'msfc 25 2'}).sort_values('mse',axis=0).reset_index().drop('index',axis=1)\n",
    "scores_to_include = [edss_scores,dd_scores,msfc251_scores,msfc252_scores]\n",
    "scores = reduce(lambda left,right: pd.merge(left,right,on=['mse','msid']),scores_to_include)\n",
    "clinical_data['metric'].unique()\n",
    "#scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge scores and lesion data\n",
    "scores_lesion = pd.merge(lesion_info,scores.drop('msid',axis=1))\n",
    "scores_lesion.fillna(0.0,inplace=True)\n",
    "#set X and y values\n",
    "X_values=scores_lesion[['inf_total_lesions','inf_total_volume_of_lesions']]\n",
    "y_values=scores_lesion.edss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn.cross_validation import train_test_split,KFold\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "import pylab as plt\n",
    "\n",
    "n_samples, n_features = X_values.shape\n",
    "n_digits = len(np.unique(y_values))\n",
    "print \"Samples: %s  Features: %s\" % (n_samples, n_features)\n",
    "\n",
    "reduced_data = PCA(n_components = 2).fit_transform(X_values)\n",
    "kmean = KMeans(n_clusters = n_digits,n_init = 3)\n",
    "kmean.fit(reduced_data)\n",
    "\n",
    "h = .02\n",
    "x_min,x_max = reduced_data[:,0].min()-1, reduced_data[:,0].max()+1\n",
    "y_min,y_max = reduced_data[:,1].min()-1, reduced_data[:,1].max()+1\n",
    "xx, yy = np.meshgrid(np.arange(x_min,x_max,h),np.arange(y_min,y_max,h))\n",
    "\n",
    "Z = kmean.predict(np.c_[xx.ravel(),yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(Z, interpolation='nearest',extent=(xx.min(),xx.max(),yy.min(),yy.max()), cmap=plt.cm.Paired,aspect='auto', origin='lower')\n",
    "plt.plot(reduced_data[:,0], reduced_data[:,1], 'k.',markersize=10)\n",
    "centroids = kmean.cluster_centers_\n",
    "plt.scatter(centroids[:,0],centroids[:,1],marker='x',s=169,linewidths=3,color='w',zorder=10)\n",
    "plt.xlim(x_min,x_max)\n",
    "plt.ylim(y_min,y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
